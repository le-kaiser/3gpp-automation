# 3GPP CR Automation Project

## Current Status
This project is actively being developed and refined to improve accuracy in detecting 3GPP Change Requests (CRs) that affect specific technical clauses. Recent improvements have focused on:

- Enhanced error handling and logging
- More robust document parsing and clause detection
- Improved handling of complex archive structures
- Better summary extraction from technical documents
- Fixed data structure syntax errors
- Removed duplicate code for better maintainability

The script is currently operational and running with the latest improvements as of October 2025.

## 1. Project Objective

This project automates the process of finding and verifying 3GPP Change Requests (CRs) that affect a specific set of technical clauses. The script browses the 3GPP FTP server, downloads relevant meeting documents, parses them to find approved CRs, and then cross-references those CRs against a local database of clauses to find relevant changes.

## 2. Workflow Overview

The script executes the following steps in sequence:

1.  **Fetch Meeting Folders**: It visits the [3GPP TSG-RAN FTP page](https://www.3gpp.org/ftp/tsg_ran/TSG_RAN) and gets a list of all meeting folders (e.g., `TSGR_109`).
2.  **Sort by Date**: It parses the modification date for each folder and sorts them in descending order, ensuring the most recent meetings are processed first.
3.  **Iterate and Search**: The script loops through each meeting folder. For each one, it attempts to:
    a. Navigate into the `/Docs/` sub-folder.
    b. Find and download the main TDoc list, which is an `.xlsx` file.
4.  **Filter Excel Data**: If an Excel file is found, the script opens the sheet named `CR_Packs_List` and filters the rows based on two criteria:
    *   The "CR Individual TSG decision" column must be **"approved"**.
    *   The "Spec" column must match the target specification number (e.g., **"38.101-1"**).
5.  **Process Archives**: For each row that matches the filter, the script extracts the **RP number** (e.g., `RP-252378`) and the **R4 document number** (e.g., `R4-2511059`). It then:
    a. Downloads the corresponding `.zip` archive (e.g., `RP-252378.zip`).
    b. Extracts the specific `.docx` file (e.g., `R4-2511059.docx`) from the archive.
6.  **Search Word Document**: The script opens the extracted `.docx` file and performs two searches:
    a. **Clauses Affected**: It looks for the "Clauses Affected" section and checks if any of the listed clauses are present in our local `CLAUSES_DATABASE`.
    b. **Summary of Change**: If a matching clause is found, it then finds the "Summary of change" section and extracts the full text of the summary.
7.  **Record Results**: If a matching clause is found, all relevant information (Meeting Folder, RP Number, R4 Document, Matching Clauses, and the Summary of Change) is stored.
8.  **Generate Report**: After checking all meeting folders, the script compiles all the recorded matches into a single Excel file named `approved_clauses.xlsx`.

## 3. Code Structure

*   `main.py`: The main Python script containing all the automation logic.
*   `requirements.txt`: A list of the required Python libraries (`requests`, `beautifulsoup4`, `pandas`, `openpyxl`, `python-docx`).
*   `.gitignore`: Configured to ignore temporary files and output reports.
*   `approved_clauses.xlsx`: The final Excel report generated by the script.
*   `temp_files/`: A directory where files are temporarily downloaded and extracted during execution.

### Key Functions in `main.py`

*   `get_sorted_meeting_folders()`: Scrapes the main FTP page and returns a date-sorted list of meeting folder URLs.
*   `find_excel_in_docs()`: Navigates into a `/Docs/` URL and downloads the primary `.xlsx` file.
*   `filter_approved_crs()`: Uses `pandas` to open and filter the Excel sheet for relevant CRs.
*   `process_rp_archive()`: Downloads a `.zip` archive, finds the correct `.docx` file inside, and extracts it.
*   `search_docx_for_clauses()`: Opens a `.docx` file to find matching clauses and extract the summary of changes.
*   `main()`: The main function that orchestrates the entire workflow from start to finish.

## 4. Configuration

The following variables can be easily modified at the top of `main.py` to change the script's behavior:

*   `SPEC_NUMBER`: The specific 3GPP specification you are targeting.
*   `CLAUSES_DATABASE`: A Python `set` containing the clause numbers you want to find matches for.
*   `OUTPUT_FILE`: The name of the final Excel report file.

## 5. How to Run

1.  Ensure all required libraries are installed by running:
    ```bash
    pip install -r requirements.txt
    ```
2.  Execute the main script from your terminal:
    ```bash
    python3 main.py
    ```

The script will print its progress to the console and will generate the `approved_clauses.xlsx` file upon completion if any matches are found.

## 6. Recent Progress and Improvements

### Key Updates Made:
- **Enhanced Error Handling**: Improved error handling for file downloads, ZIP extraction, and document processing with better logging
- **Improved Document Processing**: Enhanced logic for finding clauses in complex document structures with better regex patterns
- **Better Summary Extraction**: Advanced logic to locate and extract "Summary of change" sections more accurately
- **Nesting Support**: Added support for nested ZIP files containing the target .docx documents
- **Timestamped Logging**: Updated logging system to include timestamps for better progress tracking
- **Fixed Data Structure Issue**: Corrected syntax error in CLAUSES_DATABASE set where a comma was missing
- **Removed Duplicate Code**: Eliminated duplicate function definitions to improve maintainability
- **Enhanced Progress Tracking**: Added detailed progress reporting showing completed vs pending tasks
- **Robust Archive Processing**: Improved handling of various archive structures and file naming conventions

### Technical Improvements:
- More sophisticated clause matching algorithm that handles various formatting and spacing issues
- Better handling of case-insensitive matching and whitespace normalization
- Improved detection of clause numbers in different document sections
- Enhanced cleanup of temporary files after processing
- More resilient download mechanisms with timeout handling
